{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Convolutional_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki6an/Machine_Learning-2/blob/master/Deep%20Learning/Convolutional%20Neural%20Networks/Convolutional_Neural_Network_all_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:36.345988Z",
          "start_time": "2020-08-06T06:11:36.341001Z"
        },
        "id": "6zl12SjCM-26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:36.711523Z",
          "start_time": "2020-08-06T06:11:36.705537Z"
        },
        "id": "4rwGbl05M-2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:36.951139Z",
          "start_time": "2020-08-06T06:11:36.945156Z"
        },
        "id": "Zih64Km7M-3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO_5yKcRM-3F",
        "colab_type": "text"
      },
      "source": [
        "- `convolution` &  `pooling` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:37.631320Z",
          "start_time": "2020-08-06T06:11:37.597410Z"
        },
        "id": "wp1dJNqvM-3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.add(Conv2D(16, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooaLrIgRM-3N",
        "colab_type": "text"
      },
      "source": [
        "- `adding second convolution layer and  max pooling` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:39.317258Z",
          "start_time": "2020-08-06T06:11:39.279360Z"
        },
        "id": "NGnBuJ_HM-3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI2LRmB4fO-K",
        "colab_type": "text"
      },
      "source": [
        "- `adding third convolution layer and  max pooling` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve84CUhgfKao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_h1AzcyM-3R",
        "colab_type": "text"
      },
      "source": [
        "- `flattening`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:41.113173Z",
          "start_time": "2020-08-06T06:11:41.101204Z"
        },
        "id": "Gq7LzBmRM-3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-FCccSdM-3W",
        "colab_type": "text"
      },
      "source": [
        "- `full connection`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:44.101964Z",
          "start_time": "2020-08-06T06:11:44.055091Z"
        },
        "id": "8oMeQhHwM-3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # hidden layer\n",
        "# classifier.add(Dense(activation='relu', units=512))  # input features\n",
        "\n",
        "# # classifier.add(Dense(activation='relu', units=64))\n",
        "\n",
        "# # last layer / output layer\n",
        "# # sigmoid coz we have only 1 output, if the o/p was more than 2 use softmax\n",
        "# classifier.add(Dense(activation='sigmoid', units=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:47.065721Z",
          "start_time": "2020-08-06T06:11:46.998756Z"
        },
        "id": "vMIBIV2zM-3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.compile(RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqmtnF9HhE4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "classifier.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBMpHQDM-3h",
        "colab_type": "text"
      },
      "source": [
        "- `image augmentation technique to overcome over-fitting `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhIBOwFWNOR5",
        "colab_type": "text"
      },
      "source": [
        "- `Importing the data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4P_SRiOU7Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "481b0525-5104-4f1c-e0af-73dd38e1152f"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-15 07:29:35--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.78.216.154, 2600:1417:76:58e::e59, 2600:1417:76:586::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.78.216.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M   105MB/s    in 7.5s    \n",
            "\n",
            "2020-08-15 07:29:43 (105 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH2HMDFnW3R-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04ec64f7-1d2b-4004-8351-bec01472db17"
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W71dbi0_W6uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAMiQYy2W9GO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03c3a444-bf16-4da3-ae4d-98e0e87fe049"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7Il0__XEdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "886621ce-0c25-4aeb-bdd6-752749cb3a65"
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rtaDYGnNsU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d051493-fc3f-4c20-fb1d-ef0f414c877f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                                  rescale=1./255,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "train = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=250,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
        "test = train_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                          batch_size=250,\n",
        "                                          class_mode='binary',\n",
        "                                          target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:12:32.822526Z",
          "start_time": "2020-08-06T06:12:32.817538Z"
        },
        "id": "INYixcvuM-3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_steps = train.n // 32  # 2000/32\n",
        "# test_steps = test.n // 32  # 1000/32\n",
        "# print(train_steps, test_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:11:48.551989Z",
          "start_time": "2020-08-06T06:11:48.547001Z"
        },
        "id": "153vwH5WM-3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tboard_log_dir = os.path.join(\"logs\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tboard_log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:31:53.782072Z",
          "start_time": "2020-08-06T06:12:33.151952Z"
        },
        "scrolled": false,
        "id": "SxLhxJHBM-3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bbbcae7-ca06-4cd7-9d78-eff275e969fc"
      },
      "source": [
        "classifier.fit(\n",
        "    train,\n",
        "    steps_per_epoch=90,\n",
        "    epochs=30,  \n",
        "    validation_data=test,\n",
        "    validation_steps=6,\n",
        "    callbacks=[tensorboard_callback])\n",
        "\n",
        "\n",
        "\n",
        "# history = model.fit(train_generator, epochs=15, steps_per_epoch=90,\n",
        "#                     validation_data=validation_generator, validation_steps=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 1/90 [..............................] - ETA: 0s - loss: 0.6947 - acc: 0.4800WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            " 2/90 [..............................] - ETA: 13s - loss: 7.6126 - acc: 0.4980WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0902s vs `on_train_batch_end` time: 0.2029s). Check your callbacks.\n",
            "54/90 [=================>............] - ETA: 1:11 - loss: 0.9679 - acc: 0.5711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 197s 2s/step - loss: 0.8530 - acc: 0.5883 - val_loss: 0.6390 - val_acc: 0.6633\n",
            "Epoch 2/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.6337 - acc: 0.6601 - val_loss: 0.5886 - val_acc: 0.7007\n",
            "Epoch 3/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.5866 - acc: 0.7036 - val_loss: 0.5085 - val_acc: 0.7573\n",
            "Epoch 4/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.5406 - acc: 0.7337 - val_loss: 0.4972 - val_acc: 0.7567\n",
            "Epoch 5/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.4990 - acc: 0.7571 - val_loss: 0.4925 - val_acc: 0.7533\n",
            "Epoch 6/20\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.4637 - acc: 0.7780 - val_loss: 0.4349 - val_acc: 0.7947\n",
            "Epoch 7/20\n",
            "90/90 [==============================] - 186s 2s/step - loss: 0.4515 - acc: 0.7860 - val_loss: 0.4478 - val_acc: 0.7827\n",
            "Epoch 8/20\n",
            "90/90 [==============================] - 185s 2s/step - loss: 0.4265 - acc: 0.8006 - val_loss: 0.4845 - val_acc: 0.7773\n",
            "Epoch 9/20\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.4134 - acc: 0.8097 - val_loss: 0.5243 - val_acc: 0.7440\n",
            "Epoch 10/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3960 - acc: 0.8211 - val_loss: 0.4389 - val_acc: 0.7880\n",
            "Epoch 11/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.3823 - acc: 0.8266 - val_loss: 0.3942 - val_acc: 0.8207\n",
            "Epoch 12/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.3645 - acc: 0.8355 - val_loss: 0.4090 - val_acc: 0.8227\n",
            "Epoch 13/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.3481 - acc: 0.8478 - val_loss: 0.4291 - val_acc: 0.8167\n",
            "Epoch 14/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3376 - acc: 0.8487 - val_loss: 0.4015 - val_acc: 0.8180\n",
            "Epoch 15/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.3205 - acc: 0.8598 - val_loss: 0.4398 - val_acc: 0.7993\n",
            "Epoch 16/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3102 - acc: 0.8671 - val_loss: 0.3377 - val_acc: 0.8520\n",
            "Epoch 17/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2939 - acc: 0.8723 - val_loss: 0.3493 - val_acc: 0.8487\n",
            "Epoch 18/20\n",
            "90/90 [==============================] - 193s 2s/step - loss: 0.2842 - acc: 0.8769 - val_loss: 0.3567 - val_acc: 0.8413\n",
            "Epoch 19/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2731 - acc: 0.8843 - val_loss: 0.3366 - val_acc: 0.8520\n",
            "Epoch 20/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2650 - acc: 0.8871 - val_loss: 0.3305 - val_acc: 0.8487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7c155d87f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 1/90 [..............................] - ETA: 0s - loss: 0.6947 - acc: 0.4800WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            " 2/90 [..............................] - ETA: 13s - loss: 7.6126 - acc: 0.4980WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0902s vs `on_train_batch_end` time: 0.2029s). Check your callbacks.\n",
            "54/90 [=================>............] - ETA: 1:11 - loss: 0.9679 - acc: 0.5711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 197s 2s/step - loss: 0.8530 - acc: 0.5883 - val_loss: 0.6390 - val_acc: 0.6633\n",
            "Epoch 2/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.6337 - acc: 0.6601 - val_loss: 0.5886 - val_acc: 0.7007\n",
            "Epoch 3/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.5866 - acc: 0.7036 - val_loss: 0.5085 - val_acc: 0.7573\n",
            "Epoch 4/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.5406 - acc: 0.7337 - val_loss: 0.4972 - val_acc: 0.7567\n",
            "Epoch 5/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.4990 - acc: 0.7571 - val_loss: 0.4925 - val_acc: 0.7533\n",
            "Epoch 6/20\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.4637 - acc: 0.7780 - val_loss: 0.4349 - val_acc: 0.7947\n",
            "Epoch 7/20\n",
            "90/90 [==============================] - 186s 2s/step - loss: 0.4515 - acc: 0.7860 - val_loss: 0.4478 - val_acc: 0.7827\n",
            "Epoch 8/20\n",
            "90/90 [==============================] - 185s 2s/step - loss: 0.4265 - acc: 0.8006 - val_loss: 0.4845 - val_acc: 0.7773\n",
            "Epoch 9/20\n",
            "90/90 [==============================] - 187s 2s/step - loss: 0.4134 - acc: 0.8097 - val_loss: 0.5243 - val_acc: 0.7440\n",
            "Epoch 10/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3960 - acc: 0.8211 - val_loss: 0.4389 - val_acc: 0.7880\n",
            "Epoch 11/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.3823 - acc: 0.8266 - val_loss: 0.3942 - val_acc: 0.8207\n",
            "Epoch 12/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.3645 - acc: 0.8355 - val_loss: 0.4090 - val_acc: 0.8227\n",
            "Epoch 13/20\n",
            "90/90 [==============================] - 196s 2s/step - loss: 0.3481 - acc: 0.8478 - val_loss: 0.4291 - val_acc: 0.8167\n",
            "Epoch 14/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3376 - acc: 0.8487 - val_loss: 0.4015 - val_acc: 0.8180\n",
            "Epoch 15/20\n",
            "90/90 [==============================] - 195s 2s/step - loss: 0.3205 - acc: 0.8598 - val_loss: 0.4398 - val_acc: 0.7993\n",
            "Epoch 16/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.3102 - acc: 0.8671 - val_loss: 0.3377 - val_acc: 0.8520\n",
            "Epoch 17/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2939 - acc: 0.8723 - val_loss: 0.3493 - val_acc: 0.8487\n",
            "Epoch 18/20\n",
            "90/90 [==============================] - 193s 2s/step - loss: 0.2842 - acc: 0.8769 - val_loss: 0.3567 - val_acc: 0.8413\n",
            "Epoch 19/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2731 - acc: 0.8843 - val_loss: 0.3366 - val_acc: 0.8520\n",
            "Epoch 20/20\n",
            "90/90 [==============================] - 194s 2s/step - loss: 0.2650 - acc: 0.8871 - val_loss: 0.3305 - val_acc: 0.8487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7c155d87f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:31:53.930675Z",
          "start_time": "2020-08-06T06:31:53.908733Z"
        },
        "id": "KYz0SyfRM-3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "018f9089-1548-4c48-a50e-d07c43b45007"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-06T06:31:54.085261Z",
          "start_time": "2020-08-06T06:31:54.070300Z"
        },
        "id": "dn-aBXamM-30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "2201533e-0fa4-4ab3-fd12-2e753c5b17de"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               9470464   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 9,494,561\n",
            "Trainable params: 9,494,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               9470464   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 9,494,561\n",
            "Trainable params: 9,494,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNaNUVguM-35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = classifier.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBqvJ4HSM-38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUCs_zJYM-3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}